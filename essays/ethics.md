---
layout: essay
type: essay
title: With Great Power Comes Great Responsibiilty
date: 2017-05-2
labels:
  - Software Engineering 
  - Ethics
---

When it comes down to it the creators of our world, our engineers, artists, scientists and the like, have a great power and with that power, as the classic adage goes, comes a great responsibility. That responsibility in quesiton is a moral obligation; a creator's required adherence to create in the the name of the wellbeing of all humankind, to be consciencous of the implications both the positives and especially the negatives. When a creator becomes negligent of this responsibility, even in the most minute oversights, they can unintentionally cause disaster to occur, which in the worst case, is to cause the loss of human life. In order to prevent such disasters from occuring, fields of study and profession set ethical guidelines and rules.

The field of Software Engineering and Programming is young relative to other fields which have been in practice for hundreds of years. Nevertheless, there are ethics that must be considered in this field, as computer and software continues to increasingly pervade and effect our everday lives from simple things such as doing office work to utilizing bioinformatics to keep people alive in hospitals. It is no question that software and those who engineer have power.

## The Next Generation of Automation ##

Computers and software have been ever evolving to provide enchancements to human life, one of those facets is that of automation. Over the recent years, one of the more prominent projects in the realm of automation has been the technology being developed in self-driving cars. While self-driving cars are definitly something that the world can benefit from, they also pose high risk danger if they are not ethically designed. On the road, there are a myriad of variables to take into the grand scheme in designing the intelligence that goes into a self-driving car. It is such a chaotic environment that essentially anything can happen, and more importantly, there are things that can happen that cannot be avoided. With pedestrians, sometimes, there is no avoiding the disaster that awaits. 

Thus, in designing these self-driving cars, software engineers are placed in the unfortunate position of making decisions where the optimal choice is one with the minimum casualties. Essentially the penulitmate question is this: "In the event of an unavoidable accident, who should be the one to die?". And what makes this entire situation even more complex is the fact that the driver's life is also taken into account; there are cases in which the optimal choice for the car make is to sacrifice the driver rather than the pedestrians that the car would otherwise collide with. While this is a necessary consideration to be making, people would not be inclined to purchase a car that would sacrifice its driver. This probably has to do with the fact that the idea of one's own sacifice is held in the hands of artificial intelligence, rather than the owner of that life. 

As one can see, this is not only a moral issue but one that also affects business. After all, the self-driving feature is one that luxury manufactuers such as Tesla are interested in. If no one buys the product, what is the point in implementing the feature? In any case, this technology is one that requires intensive ethical care, because this is a product which can make the best or worst out of an accident. 

